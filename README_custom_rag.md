# Кастомный RAG с локальной моделью эмбеддингов

Этот проект позволяет создать оптимизированную RAG-систему с использованием:
1. Локальной модели эмбеддингов jinaai/jina-embeddings-v3
2. Google модели Gemini для генерации ответов и синтетических данных
3. Текстов из директории train_texts
4. Автоматической оптимизации параметров RAG

## Требования

- Python 3.8+
- Доступ к Google API (для использования Gemini)
- Достаточно оперативной памяти для загрузки модели эмбеддингов

## Установка

1. Клонируйте репозиторий:
```bash
git clone <url-репозитория>
cd <директория-репозитория>
```

2. Установите зависимости:
```bash
pip install -r requirements.txt
```

Или запустите скрипт `run_rag_pipeline.py`, который автоматически установит все необходимые зависимости.

## Структура проекта

- `run_rag_pipeline.py` - основной скрипт для запуска всего процесса
- `generate_synthetic_data.py` - скрипт для генерации синтетических вопросов и ответов
- `custom_rag_builder.py` - скрипт для настройки и оптимизации RAG
- `train_texts/` - директория с текстовыми файлами для обучения
- `synthetic_qa_data.csv` - сгенерированные пары вопрос-ответ (создается автоматически)
- `optimized_rag_config/` - директория с оптимизированной конфигурацией RAG (создается автоматически)

## Использование

### Быстрый старт

Для запуска всего процесса выполните:

```bash
python run_rag_pipeline.py
```

Скрипт выполнит следующие шаги:
1. Проверит и установит необходимые зависимости
2. Проверит наличие директории с текстами
3. Запросит Google API ключ (если не задан в переменных окружения)
4. Сгенерирует синтетические данные (вопросы и ответы)
5. Настроит и оптимизирует RAG
6. Запустит API-сервер для использования RAG

### Генерация только синтетических данных

Если вы хотите только сгенерировать синтетические данные:

```bash
python generate_synthetic_data.py
```

### Настройка только RAG

Если у вас уже есть синтетические данные и вы хотите только настроить RAG:

```bash
python custom_rag_builder.py
```

## Настройка параметров

### Модель эмбеддингов

По умолчанию используется модель `jinaai/jina-embeddings-v3`. Если вы хотите использовать другую модель, измените параметр `model_name` в файле `custom_rag_builder.py`:

```python
embeddings = HuggingFaceEmbeddings(
    model_name="другая-модель",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
```

### Модель генерации

По умолчанию используется модель `gemini-1.5-pro`. Если вы хотите использовать другую модель, измените параметр `model` в файле `custom_rag_builder.py` и `generate_synthetic_data.py`:

```python
llm = ChatGoogleGenerativeAI(
    model="другая-модель",
    temperature=0.2,
    convert_system_message_to_human=True
)
```

### Параметры чанкинга

Вы можете изменить параметры разбиения текста на чанки в файле `custom_rag_builder.py`:

```python
chunk_size={"min": 500, "max": 1500, "stepsize": 250},
chunk_overlap={"min": 50, "max": 200, "stepsize": 50},
```

## API-сервер

После завершения оптимизации автоматически запускается API-сервер, который доступен по адресу `http://localhost:8000`.

Вы можете использовать следующие эндпоинты:
- `POST /query` - для отправки запросов к RAG-системе
- `GET /docs` - для просмотра документации API

## Устранение неполадок

### Проблемы с Google API

Если вы получаете ошибки, связанные с Google API, убедитесь, что:
1. У вас есть действующий API ключ
2. Ключ имеет доступ к Gemini API
3. Ключ правильно указан в переменной окружения `GOOGLE_API_KEY`

### Проблемы с памятью

Если вы получаете ошибки, связанные с нехваткой памяти:
1. Попробуйте использовать модель эмбеддингов меньшего размера
2. Уменьшите размер чанков в параметрах
3. Запустите на машине с большим объемом оперативной памяти

### Другие проблемы

Если у вас возникают другие проблемы, проверьте логи для получения дополнительной информации. Логи выводятся в консоль и содержат подробную информацию о каждом шаге процесса. 