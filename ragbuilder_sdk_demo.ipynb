{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGBuilder Optimization Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragbuilder\n",
      "  Downloading ragbuilder-0.1.5-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting chromadb (from ragbuilder)\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets>=2.18.0 (from ragbuilder)\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fastapi>=0.100.0 (from ragbuilder)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting jinja2 (from ragbuilder)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain>=0.1.0 (from ragbuilder)\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting langchain-community==0.2.7 (from ragbuilder)\n",
      "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core==0.2.20 (from ragbuilder)\n",
      "  Downloading langchain_core-0.2.20-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-huggingface==0.0.3 (from ragbuilder)\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langchain-openai==0.1.17 (from ragbuilder)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.23.0 (from ragbuilder)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk>=1.23.0 (from ragbuilder)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp>=1.23.0 (from ragbuilder)\n",
      "  Downloading opentelemetry_exporter_otlp-1.30.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting optuna (from ragbuilder)\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.13/site-packages (from ragbuilder) (4.3.6)\n",
      "Collecting pydantic>=2.0.0 (from ragbuilder)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting python-dotenv (from ragbuilder)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ragas==0.1.7 (from ragbuilder)\n",
      "  Downloading ragas-0.1.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting rerankers (from ragbuilder)\n",
      "  Downloading rerankers-0.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting rich>=13.0.0 (from ragbuilder)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentence-transformers (from ragbuilder)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tenacity==8.4.2 (from ragbuilder)\n",
      "  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting rank-bm25 (from ragbuilder)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting uvicorn>=0.30.0 (from ragbuilder)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading SQLAlchemy-2.0.38-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading aiohttp-3.11.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain>=0.1.0 (from ragbuilder)\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_14_0_arm64.whl\n",
      "Collecting requests<3,>=2 (from langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.2.20->ragbuilder)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core==0.2.20->ragbuilder) (24.2)\n",
      "Collecting huggingface-hub>=0.23.0 (from langchain-huggingface==0.0.3->ragbuilder)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface==0.0.3->ragbuilder)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface==0.0.3->ragbuilder)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai==0.1.17->ragbuilder)\n",
      "  Downloading openai-1.65.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.1.17->ragbuilder)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.7->ragbuilder)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.13/site-packages (from ragas==0.1.7->ragbuilder) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.1.7->ragbuilder)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.18.0->ragbuilder)\n",
      "  Downloading pyarrow-19.0.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.18.0->ragbuilder)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.18.0->ragbuilder)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.100.0->ragbuilder)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi>=0.100.0->ragbuilder)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain>=0.1.0 (from ragbuilder)\n",
      "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain-0.2.9-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain>=0.1.0->ragbuilder)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.23.0->ragbuilder)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.23.0->ragbuilder)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.30.0 (from opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.30.0 (from opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.63.2 (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.23.0->ragbuilder)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk>=1.23.0->ragbuilder)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->ragbuilder)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.0.0->ragbuilder)\n",
      "  Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.0.0->ragbuilder)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich>=13.0.0->ragbuilder) (2.19.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers->ragbuilder)\n",
      "  Using cached torch-2.6.0-cp313-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers->ragbuilder)\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers->ragbuilder)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting Pillow (from sentence-transformers->ragbuilder)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting click>=7.0 (from uvicorn>=0.30.0->ragbuilder)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.30.0->ragbuilder)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb->ragbuilder)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb->ragbuilder)\n",
      "  Downloading chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb->ragbuilder)\n",
      "  Downloading posthog-3.19.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb->ragbuilder)\n",
      "  Downloading onnxruntime-1.21.0-cp313-cp313-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->ragbuilder)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb->ragbuilder)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb->ragbuilder)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb->ragbuilder)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb->ragbuilder)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb->ragbuilder)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb->ragbuilder)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb->ragbuilder)\n",
      "  Downloading mmh3-5.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb->ragbuilder)\n",
      "  Downloading orjson-3.10.15-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb->ragbuilder)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->ragbuilder)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna->ragbuilder)\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna->ragbuilder)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->ragbuilder)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb->ragbuilder)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.7->ragbuilder)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api>=1.23.0->ragbuilder)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->chromadb->ragbuilder)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx>=0.27.0->chromadb->ragbuilder)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb->ragbuilder)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27.0->chromadb->ragbuilder)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.23.0->ragbuilder)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.2.20->ragbuilder)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb->ragbuilder) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb->ragbuilder) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting urllib3>=1.24.2 (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain>=0.1.0->ragbuilder)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.0.0->ragbuilder)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.17->ragbuilder)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.17->ragbuilder)\n",
      "  Downloading jiter-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.17->ragbuilder)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->ragbuilder)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->ragbuilder)\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->ragbuilder)\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->ragbuilder)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->ragbuilder)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->ragbuilder)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.1.17->ragbuilder)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers->ragbuilder)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers->ragbuilder)\n",
      "  Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.39.0->langchain-huggingface==0.0.3->ragbuilder)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb->ragbuilder)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb->ragbuilder)\n",
      "  Downloading httptools-0.6.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->ragbuilder)\n",
      "  Downloading uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->ragbuilder)\n",
      "  Downloading watchfiles-1.0.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->ragbuilder)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=2.18.0->ragbuilder)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.18.0->ragbuilder)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers->ragbuilder)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers->ragbuilder)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.7->ragbuilder)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->ragbuilder)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->ragbuilder)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading ragbuilder-0.1.5-py3-none-any.whl (519 kB)\n",
      "Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.20-py3-none-any.whl (371 kB)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
      "Downloading ragas-0.1.7-py3-none-any.whl (81 kB)\n",
      "Downloading tenacity-8.4.2-py3-none-any.whl (28 kB)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Downloading langchain-0.2.9-py3-none-any.whl (987 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.7/987.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.30.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading rerankers-0.8.0-py3-none-any.whl (47 kB)\n",
      "Downloading aiohttp-3.11.13-cp313-cp313-macosx_11_0_arm64.whl (453 kB)\n",
      "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl (498 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading mmh3-5.1.0-cp313-cp313-macosx_11_0_arm64.whl (40 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading onnxruntime-1.21.0-cp313-cp313-macosx_13_0_universal2.whl (33.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.65.5-py3-none-any.whl (474 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading orjson-3.10.15-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.19.1-py2.py3-none-any.whl (77 kB)\n",
      "Downloading pyarrow-19.0.1-cp313-cp313-macosx_12_0_arm64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached torch-2.6.0-cp313-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl (195 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Using cached frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl (50 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Downloading httptools-0.6.4-cp313-cp313-macosx_11_0_arm64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.4-cp313-cp313-macosx_11_0_arm64.whl (381 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl (91 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib, pypika\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.6-cp313-cp313-macosx_14_0_arm64.whl size=190608 sha256=855cbfde2a62547397207917dfefa7dd3af05be95b3a4e029d15c8a8e74141f2\n",
      "  Stored in directory: /Users/evgeniigutin/Library/Caches/pip/wheels/e4/de/05/47d2e8cd71d86b683765286c3308516ddcb7e8bf7db44fa69f\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=b45dd14873036447a68a9ad9d75127947d18827f5b040aaa4208db9942973ccd\n",
      "  Stored in directory: /Users/evgeniigutin/Library/Caches/pip/wheels/b4/f8/a5/28e9c1524d320f4b8eefdce0e487b5c2e128dbf2ed1bb4a60b\n",
      "Successfully built chroma-hnswlib pypika\n",
      "Installing collected packages: pytz, pypika, mpmath, monotonic, flatbuffers, durationpy, appdirs, zipp, xxhash, wrapt, websockets, websocket-client, uvloop, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, sniffio, shellingham, setuptools, safetensors, rerankers, regex, PyYAML, python-dotenv, pysbd, pyproject_hooks, pyasn1, pyarrow, protobuf, propcache, Pillow, overrides, orjson, opentelemetry-util-http, oauthlib, numpy, networkx, mypy-extensions, multidict, mmh3, mdurl, marshmallow, MarkupSafe, jsonpointer, joblib, jiter, importlib-resources, idna, humanfriendly, httptools, h11, grpcio, fsspec, frozenlist, filelock, distro, dill, colorlog, click, charset-normalizer, certifi, cachetools, bcrypt, backoff, attrs, asgiref, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, SQLAlchemy, scipy, rsa, requests, rank-bm25, pydantic-core, pyasn1-modules, pandas, opentelemetry-proto, multiprocess, markdown-it-py, Mako, jsonpatch, jinja2, importlib-metadata, httpcore, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, build, anyio, aiosignal, watchfiles, torch, tiktoken, starlette, scikit-learn, rich, requests-toolbelt, requests-oauthlib, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, huggingface-hub, httpx, google-auth, dataclasses-json, alembic, aiohttp, typer, tokenizers, optuna, opentelemetry-semantic-conventions, openai, langsmith, kubernetes, fastapi, transformers, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, datasets, sentence-transformers, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp, langchain-huggingface, langchain, langchain-community, chromadb, ragas, ragbuilder\n",
      "Successfully installed Mako-1.3.9 MarkupSafe-3.0.2 Pillow-11.1.0 PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.5.0 aiohttp-3.11.13 aiosignal-1.3.2 alembic-1.15.1 annotated-types-0.7.0 anyio-4.8.0 appdirs-1.4.4 asgiref-3.8.1 attrs-25.1.0 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 chroma-hnswlib-0.7.6 chromadb-0.6.3 click-8.1.8 coloredlogs-15.0.1 colorlog-6.9.0 dataclasses-json-0.6.7 datasets-3.3.2 deprecated-1.2.18 dill-0.3.8 distro-1.9.0 durationpy-0.9 fastapi-0.115.11 filelock-3.17.0 flatbuffers-25.2.10 frozenlist-1.5.0 fsspec-2024.12.0 google-auth-2.38.0 googleapis-common-protos-1.69.1 grpcio-1.71.0 h11-0.14.0 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 huggingface-hub-0.29.2 humanfriendly-10.0 idna-3.10 importlib-metadata-8.5.0 importlib-resources-6.5.2 jinja2-3.1.6 jiter-0.9.0 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-32.0.1 langchain-0.2.9 langchain-community-0.2.7 langchain-core-0.2.20 langchain-huggingface-0.0.3 langchain-openai-0.1.17 langchain-text-splitters-0.2.2 langsmith-0.1.147 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 mypy-extensions-1.0.0 networkx-3.4.2 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.21.0 openai-1.65.5 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-exporter-otlp-proto-http-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 optuna-4.2.1 orjson-3.10.15 overrides-7.7.0 pandas-2.2.3 posthog-3.19.1 propcache-0.3.0 protobuf-5.29.3 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.6 pydantic-core-2.27.2 pypika-0.48.9 pyproject_hooks-1.2.0 pysbd-0.3.4 python-dotenv-1.0.1 pytz-2025.1 ragas-0.1.7 ragbuilder-0.1.5 rank-bm25-0.2.2 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rerankers-0.8.0 rich-13.9.4 rsa-4.9 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 setuptools-76.0.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.46.1 sympy-1.13.1 tenacity-8.4.2 threadpoolctl-3.5.0 tiktoken-0.9.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0 typer-0.15.2 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2025.1 urllib3-2.3.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First clone the RAGBuilder repo\n",
    "!pip install ragbuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart - Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgeniigutin/Desktop/ragi/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from ragbuilder import RAGBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_st'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/sentence_transformers/util.py:1140\u001b[39m, in \u001b[36mimport_from_string\u001b[39m\u001b[34m(dotted_path)\u001b[39m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdotted_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1310\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'custom_st'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m      5\u001b[39m llm=ChatOpenAI(model=\u001b[33m'\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m'\u001b[39m, temperature=\u001b[32m0.2\u001b[39m, api_key=\u001b[33m\"\u001b[39m\u001b[33msk-proj-8LdvEO-teoX45VlfUt30MWTeiQV-jtG0HvbfIKpL0hgWD_n-Am6rE0SjtOpahe-f80K_H2o9FcT3BlbkFJ-8_knC7m-_wgvyg6RGb87yhvN2fS03C2otgEUFXQg-g2G4e0TjQZY-ooMQtmZB_4elsl2iFewA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m emb=\u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjinaai/jina-embeddings-v3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnormalize_embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/langchain_huggingface/embeddings/huggingface.py:61\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     57\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     58\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43msentence_transformers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:308\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    299\u001b[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + model_name_or_path\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[32m    302\u001b[39m     model_name_or_path,\n\u001b[32m    303\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    307\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    320\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    321\u001b[39m         model_name_or_path,\n\u001b[32m    322\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    329\u001b[39m         config_kwargs=config_kwargs,\n\u001b[32m    330\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1672\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[32m   1671\u001b[39m     class_ref = module_config[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1672\u001b[39m     module_class = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_module_class_from_ref\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1676\u001b[39m     \u001b[38;5;66;03m# For Transformer, don't load the full directory, rely on `transformers` instead\u001b[39;00m\n\u001b[32m   1677\u001b[39m     \u001b[38;5;66;03m# But, do load the config file first.\u001b[39;00m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module_config[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1577\u001b[39m, in \u001b[36mSentenceTransformer._load_module_class_from_ref\u001b[39m\u001b[34m(self, class_ref, model_name_or_path, trust_remote_code, revision, model_kwargs)\u001b[39m\n\u001b[32m   1573\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1574\u001b[39m         \u001b[38;5;66;03m# Ignore the error if 1) the file does not exist, or 2) the class_ref is not correctly formatted/found\u001b[39;00m\n\u001b[32m   1575\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimport_from_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ragi/venv/lib/python3.13/site-packages/sentence_transformers/util.py:1142\u001b[39m, in \u001b[36mimport_from_string\u001b[39m\u001b[34m(dotted_path)\u001b[39m\n\u001b[32m   1140\u001b[39m     module = importlib.import_module(dotted_path)\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1142\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'custom_st'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "llm=ChatOpenAI(model='gpt-4o-mini', temperature=0.2, api_key=\"\")\n",
    "emb=HuggingFaceEmbeddings(\n",
    "    model_name=\"jinaai/jina-embeddings-v3\",\n",
    "    model_kwargs={\"device\": \"gpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = RAGBuilder.from_source_with_defaults(\n",
    "    input_source='https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "    test_dataset=\"rag_test_data_lilianweng_gpt-4o_1721032414.736622.csv\",\n",
    "    default_llm=llm,\n",
    "    default_embeddings=emb,\n",
    "    n_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f939e588feb84039b090f17ae858ca19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Data Ingestion Optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Data Ingestion Optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ─────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:39,355] A new study created in RDB with name: data_ingest_1735663839280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2252d49b76f43e5b54ce279f6b726de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d75c0dfb52a4d1da2495c8cac0f7969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8156</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.8156\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:47,057] Trial 0 finished with value: 0.8156415328383447 and parameters: {'chunk_size': 1000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7929</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7929\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:50,786] Trial 1 finished with value: 0.7929137279589971 and parameters: {'chunk_size': 3000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bed8e5c8105401b8f460ac5220805db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7926</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7926\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,317] Trial 2 finished with value: 0.7926271418730417 and parameters: {'chunk_size': 2500}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:20:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7926271418730417</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:20:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7926271418730417\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,336] Trial 3 finished with value: 0.7926271418730417 and parameters: {'chunk_size': 2500}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7929137279589971</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7929137279589971\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,351] Trial 4 finished with value: 0.7929137279589971 and parameters: {'chunk_size': 3000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8156</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Best Parameters:</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'chunk_size'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1000</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.8156\u001b[0m\n",
       "\u001b[32mBest Parameters:\u001b[0m\n",
       "\u001b[1;96m{\u001b[0m\u001b[96m'chunk_size'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m1000\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Successfully optimized and cached best configuration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Successfully optimized and cached best configuration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:20:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:20:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting retriever optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting retriever optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:59,424] A new study created in RDB with name: retriever_1735663859509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe94e1ab54465e96f34372d615616d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2858c774ef944c5e95b0df92d2e964f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:10,368] Trial 0 finished with value: 0.9999999999716667 and parameters: {'n_retrievers': 1, 'retriever_0_index': 0, 'final_k': 5}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb37dba9a8504012adefcc1f7a69bd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.941</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.889</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.941\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.889\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:17,823] Trial 1 finished with value: 0.9411764705636293 and parameters: {'n_retrievers': 2, 'retriever_0_index': 1, 'retriever_1_index': 0, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3d7b094604df695641239a7453ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.875</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.778</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.875\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.778\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:25,303] Trial 2 finished with value: 0.8749999999702256 and parameters: {'n_retrievers': 1, 'retriever_0_index': 1, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623acd1135c44c93ab658812f9399db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.941</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.889</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.941\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.889\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:32,750] Trial 3 finished with value: 0.9411764705611687 and parameters: {'n_retrievers': 1, 'retriever_0_index': 0, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8749999999702256</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.8749999999702256\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:32,770] Trial 4 finished with value: 0.8749999999702256 and parameters: {'n_retrievers': 1, 'retriever_0_index': 1, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">✓ Optimization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27m✓ Optimization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1.0000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m1.0000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'retrievers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'vector_similarity'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'top_k'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'rerankers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'BAAI/bge-reranker-base'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\u001b[32m'retrievers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'vector_similarity'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'top_k'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'rerankers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'BAAI/bge-reranker-base'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:34] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Generation Optimization</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Generation Optimization\u001b[0m\u001b[92m ─────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> trial configurations                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generated \u001b[1;36m5\u001b[0m trial configurations                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m0\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m0\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m1\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m1\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:46] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m2\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m2\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m3\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m3\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m4\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m4\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2cc7a08d2d437a9fe086a69d434ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:22:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating prompt results                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:22:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating prompt results                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8693af6631e4ea7bb83c170766a04c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:22:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating final prompt testing results                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:22:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating final prompt testing results                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Average correctness results saved to <span style=\"color: #008000; text-decoration-color: #008000\">'rag_average_correctness_20241231_222242.csv'</span>             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Average correctness results saved to \u001b[32m'rag_average_correctness_20241231_222242.csv'\u001b[0m             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7404</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.7404\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'AzureChatOpenAI:gpt-4o-mini'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_template'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a highly accurate assistant. Respond only with the facts found in the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context. \\nIf there is insufficient information in the context, say \"I don\\'t </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">know.\"\\n\\n&lt;context&gt;\\n{context}\\n&lt;/context&gt;\\n'</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'model'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'AzureChatOpenAI:gpt-4o-mini'\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'temperature'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'prompt_template'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'You are a highly accurate assistant. Respond only with the facts found in the provided \u001b[0m\n",
       "\u001b[32mcontext. \\nIf there is insufficient information in the context, say \"I don\\'t \u001b[0m\n",
       "\u001b[32mknow.\"\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</context\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n'\u001b[0m\n",
       "\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results =builder.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = results.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is HNSW?\n",
      "Answer: HNSW (Hierarchical Navigable Small World) is a data structure inspired by small world networks, where most nodes can be reached from any other node within a small number of steps. It builds hierarchical layers of small-world graphs, with the bottom layers containing actual data points. The middle layers create shortcuts to speed up search. During a search, HNSW starts from a random node in the top layer and navigates towards the target, moving down layers until it reaches the bottom layer. Moves in the upper layers can cover large distances in the data space, while moves in the lower layers refine the search quality.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {response['question']}\\nAnswer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_ingest\": {\n",
      "    \"score\": 0.8156415328383447,\n",
      "    \"optimization_time\": 16.987402,\n",
      "    \"config\": {\n",
      "      \"document_loader\": \"unstructured\",\n",
      "      \"chunking_strategy\": \"RecursiveCharacterTextSplitter\",\n",
      "      \"chunk_size\": 1000,\n",
      "      \"chunk_overlap\": 100,\n",
      "      \"embedding_model\": \"EmbeddingType.HUGGINGFACE:mixedbread-ai/mxbai-embed-large-v1\",\n",
      "      \"vector_database\": \"chroma\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 127.93433333333333,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"retrieval\": {\n",
      "    \"score\": 0.9999999999716667,\n",
      "    \"optimization_time\": 33.336164,\n",
      "    \"config\": {\n",
      "      \"retrievers\": [\n",
      "        \"vector_similarity\"\n",
      "      ],\n",
      "      \"top_k\": 5,\n",
      "      \"rerankers\": [\n",
      "        \"BAAI/bge-reranker-base\"\n",
      "      ]\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 451.14433333333335,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"score\": 0.7403833697261465,\n",
      "    \"optimization_time\": 68.449513,\n",
      "    \"config\": {\n",
      "      \"model\": \"AzureChatOpenAI:gpt-4o-mini\",\n",
      "      \"temperature\": 0.2,\n",
      "      \"prompt_template\": \"You are a highly accurate assistant. Respond only with the facts found in the provided context. \\nIf there is insufficient information in the context, say \\\"I don't know.\\\"\\n\\n<context>\\n{context}\\n</context>\\n\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": null,\n",
      "      \"error_rate\": null\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install pymupdf pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_builder = RAGBuilder(\n",
    "    default_llm=llm,\n",
    "    default_embeddings=emb,\n",
    "    n_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragbuilder.config import (\n",
    "    DataIngestOptionsConfig,\n",
    "    RetrievalOptionsConfig,\n",
    "    GenerationOptionsConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a data ingestion configuration with more options (Eg: multiple parsers/loaders, knowledge graph, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingest_config = DataIngestOptionsConfig(\n",
    "    input_source=\"lillog_agents.pdf\",\n",
    "    document_loaders=[\n",
    "        {\"type\": \"pymupdf\"},\n",
    "        {\"type\": \"unstructured\"},\n",
    "        {\"type\": \"pypdf\"}\n",
    "    ],\n",
    "    chunking_strategies=[\n",
    "        {\n",
    "            \"type\": \"RecursiveCharacterTextSplitter\",\n",
    "            \"chunker_kwargs\": {\"separators\": [\"\\n\\n\", \"\\n\", \" \", \"\"]}\n",
    "        }\n",
    "    ],\n",
    "    chunk_size={\n",
    "        \"min\": 500,\n",
    "        \"max\": 3000,\n",
    "        \"stepsize\": 500\n",
    "    },\n",
    "    chunk_overlap=[100],\n",
    "    embedding_models=[\n",
    "        {\n",
    "            \"type\": \"azure_openai\",\n",
    "            \"model_kwargs\": {\n",
    "                \"model\": \"text-embedding-3-large\",\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    vector_databases=[\n",
    "        {\n",
    "            \"type\": \"chroma\",\n",
    "            \"vectordb_kwargs\": {\n",
    "                'persist_directory': 'chroma_sample2123',\n",
    "                'collection_metadata': {'hnsw:space': 'cosine'}\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    graph={\n",
    "        \"type\": \"neo4j\", # Note that you will need to have a neo4j instance running. \n",
    "                         # There's a docker compose file in the repo.\n",
    "                         # You will also need to set the NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD environment variables.\n",
    "    },\n",
    "    optimization={\n",
    "        \"n_trials\": 10,\n",
    "        \"n_jobs\": 1,\n",
    "        \"study_name\": \"lillog_agents_study\",\n",
    "        \"optimization_direction\": \"maximize\"\n",
    "    },\n",
    "    evaluation_config={\n",
    "        \"type\": \"similarity\",\n",
    "        \"test_dataset\": \"rag_test_data_lilianweng_gpt-4o_1721032414.736622.csv\",\n",
    "        \"evaluator_kwargs\": {\n",
    "            \"top_k\": 3,\n",
    "            \"relevance_threshold\": 0.2,   # Minimum relevance to consider for scoring\n",
    "            \"position_weights\": [1.0, 0.5, 0.3]  # More weight to top results\n",
    "        }\n",
    "    },\n",
    "    database_logging=True,\n",
    "    database_path=\"eval.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run only the data-ingestion related optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Data Ingestion Optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Data Ingestion Optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ─────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:29:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Overwriting existing study: lillog_agents_study                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:29:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Overwriting existing study: lillog_agents_study                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:27,421] A new study created in RDB with name: lillog_agents_study\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601e6090540b476693de9a9987a50fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782136410c114cb897d051baa940b961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.6994</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.6994\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:36,421] Trial 0 finished with value: 0.6993674072954389 and parameters: {'document_loader_index': 2, 'chunk_size': 500}. Best is trial 0 with value: 0.6993674072954389.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fb606667b7440a87b9e5d498cc7d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7543</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7543\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:40,881] Trial 1 finished with value: 0.7543484701703952 and parameters: {'document_loader_index': 2, 'chunk_size': 3000}. Best is trial 1 with value: 0.7543484701703952.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f3bfc011174be5889b5b4793b4149f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7606</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7606\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:45,793] Trial 2 finished with value: 0.7606029867262851 and parameters: {'document_loader_index': 1, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56df9584c3e84e469ce82f9c9054aa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.6950</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.6950\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:54,125] Trial 3 finished with value: 0.6949703637441452 and parameters: {'document_loader_index': 0, 'chunk_size': 500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fc5e3fbd154616baf0459f35aa4dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7509</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7509\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:59,009] Trial 4 finished with value: 0.7509295219266461 and parameters: {'document_loader_index': 2, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">5</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m5\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90a59c0ada84e45b3834e2d139a7854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7083</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7083\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:07,339] Trial 5 finished with value: 0.7083337836795384 and parameters: {'document_loader_index': 1, 'chunk_size': 500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">6</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m6\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7606029867262851</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7606029867262851\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:07,363] Trial 6 finished with value: 0.7606029867262851 and parameters: {'document_loader_index': 1, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">7</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m7\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84faae65d7424d4c83931b10d368a952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7347</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7347\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:13,127] Trial 7 finished with value: 0.7347048121641531 and parameters: {'document_loader_index': 1, 'chunk_size': 1000}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">8</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m8\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef0dd78ee794d8fb5be99781a97b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7669</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7669\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:17,423] Trial 8 finished with value: 0.7669465389795974 and parameters: {'document_loader_index': 1, 'chunk_size': 3000}. Best is trial 8 with value: 0.7669465389795974.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m9\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7543484701703952</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7543484701703952\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:17,452] Trial 9 finished with value: 0.7543484701703952 and parameters: {'document_loader_index': 2, 'chunk_size': 3000}. Best is trial 8 with value: 0.7669465389795974.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7669</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Best Parameters:</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'document_loader'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">&lt;ParserType.UNSTRUCTURED:</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'unstructured'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">&gt;</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'chunk_size'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">3000</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.7669\u001b[0m\n",
       "\u001b[32mBest Parameters:\u001b[0m\n",
       "\u001b[1;96m{\u001b[0m\u001b[96m'document_loader'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m<\u001b[0m\u001b[1;96mParserType.UNSTRUCTURED:\u001b[0m\u001b[96m \u001b[0m\u001b[96m'unstructured'\u001b[0m\u001b[1;96m>\u001b[0m\u001b[96m, \u001b[0m\u001b[96m'chunk_size'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m3000\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6b87dfc5484d4cad754c45469ae4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Loading graph...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mLoading graph\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:18<00:00,  5.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Successfully optimized and cached best configuration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Successfully optimized and cached best configuration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataIngestResults(best_config=DataIngestConfig(input_source='lillog_agents.pdf', document_loader=LoaderConfig(type=<ParserType.UNSTRUCTURED: 'unstructured'>, loader_kwargs=None, custom_class=None), chunking_strategy=ChunkingStrategyConfig(type=<ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, chunker_kwargs={'separators': ['\\n\\n', '\\n', ' ', '']}, custom_class=None), chunk_size=3000, chunk_overlap=100, embedding_model=EmbeddingConfig(type=<EmbeddingType.AZURE_OPENAI: 'azure_openai'>, model_kwargs={'model': 'text-embedding-3-large'}, custom_class=None), vector_database=VectorDBConfig(type=<VectorDatabase.CHROMA: 'chroma'>, vectordb_kwargs={'persist_directory': 'chroma_sample2123/9', 'collection_metadata': {'hnsw:space': 'cosine'}}, custom_class=None), sampling_rate=None), best_score=0.7669465389795974, best_pipeline=<ragbuilder.data_ingest.pipeline.DataIngestPipeline object at 0x56a02c740>, n_trials=10, completed_trials=10, optimization_time=50.021133, avg_latency=349.08733333333333, error_rate=0.0, best_index=<langchain_community.vectorstores.chroma.Chroma object at 0x377fc0a40>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_data_ingest(data_ingest_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We now have an optimized vector store with optimized retrievability. \n",
    "Now let's proceed to define the retrieval options config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_config = RetrievalOptionsConfig(\n",
    "    retrievers=[\n",
    "        {\n",
    "            \"type\": \"vector_similarity\", # Vector similarity search\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"bm25\",  # BM25 keyword search retriever\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"parent_doc_large\", # Parent doc retriever with large chunks as parent docs\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"graph\",  # Graph retriever using the knowledge graph\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        }\n",
    "    ],\n",
    "    rerankers=[\n",
    "        {\"type\": \"BAAI/bge-reranker-base\"},\n",
    "        {\"type\": \"mixedbread-ai/mxbai-rerank-large-v1\"}\n",
    "    ],\n",
    "    top_k=[3, 5, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:32:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:32:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting retriever optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting retriever optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:32:30,424] A new study created in RDB with name: retriever_1735664550667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b73db2e4e4f8f8a7ff2914f7d9434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model mixedbread-ai/mxbai-rerank-large-v1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535dd16cc84949c5adccd47cbadf45e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.979</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.958</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.979\u001b[0m\n",
       "Context Precision: \u001b[1;36m0.958\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:02,285] Trial 0 finished with value: 0.9787234042476052 and parameters: {'n_retrievers': 3, 'retriever_0_index': 2, 'retriever_1_index': 1, 'retriever_2_index': 3, 'use_rerankers': True, 'reranker_index': 1, 'final_k': 10}. Best is trial 0 with value: 0.9787234042476052.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model mixedbread-ai/mxbai-rerank-large-v1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abffccecc44550b9e13bc29286eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:17,136] Trial 1 finished with value: 0.9999999999805556 and parameters: {'n_retrievers': 3, 'retriever_0_index': 1, 'retriever_1_index': 1, 'retriever_2_index': 3, 'use_rerankers': True, 'reranker_index': 1, 'final_k': 3}. Best is trial 1 with value: 0.9999999999805556.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589fa80c293c495d839bc488c58cd8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:22,825] Trial 2 finished with value: 0.9999999999736111 and parameters: {'n_retrievers': 2, 'retriever_0_index': 1, 'retriever_1_index': 1, 'use_rerankers': False, 'final_k': 10}. Best is trial 1 with value: 0.9999999999805556.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea87d67e6444af5a6d45c5943ac07e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:35,182] Trial 3 finished with value: 0.9999999999833333 and parameters: {'n_retrievers': 3, 'retriever_0_index': 1, 'retriever_1_index': 3, 'retriever_2_index': 0, 'use_rerankers': True, 'reranker_index': 0, 'final_k': 3}. Best is trial 3 with value: 0.9999999999833333.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1a8f2ff1d44f99980a3450215661f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:45,328] Trial 4 finished with value: 0.9999999999805556 and parameters: {'n_retrievers': 1, 'retriever_0_index': 2, 'use_rerankers': True, 'reranker_index': 0, 'final_k': 3}. Best is trial 3 with value: 0.9999999999833333.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">✓ Optimization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27m✓ Optimization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1.0000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m1.0000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'retrievers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'bm25'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'vector_similarity'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'top_k'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'rerankers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'BAAI/bge-reranker-base'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\u001b[32m'retrievers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'bm25'\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'graph'\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'vector_similarity'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'top_k'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'rerankers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'BAAI/bge-reranker-base'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RetrievalResults(best_config=RetrievalConfig(retrievers=[BaseRetrieverConfig(type=<RetrieverType.BM25: 'bm25'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25), BaseRetrieverConfig(type=<RetrieverType.GRAPH_RETRIEVER: 'graph'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25), BaseRetrieverConfig(type=<RetrieverType.VECTOR_SIMILARITY: 'vector_similarity'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25)], rerankers=[RerankerConfig(type=<RerankerType.BGE_BASE: 'BAAI/bge-reranker-base'>, reranker_kwargs={}, custom_class=None)], top_k=3), best_score=0.9999999999833333, best_pipeline=<ragbuilder.retriever.pipeline.RetrieverPipeline object at 0x307f1ad80>, n_trials=5, completed_trials=5, optimization_time=74.894355, avg_latency=1613.4706666666668, error_rate=0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_retrieval(retrieval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'lillog_agents.pdf', 'relevance_score': 1.8486328125}, page_content=\"experiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\"),\n",
       " Document(metadata={'source': 'lillog_agents.pdf', 'vector_score': 0.5687193870544434, 'type': 'primary', 'relevance_score': 1.509765625}, page_content='[Vector Search Result - Score: 0.569]\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil\\'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nRelated Documents:\\n\\n[Graph-Connected Document - Score: 0.848]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Explicitmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Explicitmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\nDocument text: into a neural network by performing behavioral cloning over actions. The history data is generated\\n\\nby a set of source policies, each trained for a specific task. At the training stage, during each RL\\n\\nrun, a random task is sampled and a subsequence of multi-episode history is used for training,\\n\\nsuch that the learned policy is task-agnostic.\\n\\nIn reality, the model has limited context window length, so episodes should be short enough to\\n\\nconstruct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a\\n\\nnear-optimal in-context RL algorithm. The emergence of in-context RL requires long enough\\n\\ncontext.\\n\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert\\n\\ntrajectories instead of learning history), source policy (used for generating trajectories for\\n\\ndistillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD\\n\\ndemonstrates in-context RL with performance getting close to RL^2 despite only using offline RL\\n\\nand learns much faster than other baselines. When conditioned on partial training history of the\\n\\nsource policy, AD also improves much faster than ED baseline.\\n\\nLil\\'Log\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze. (Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory\\n\\n(Big thank you to ChatGPT for helping me draft this section. Iʼve learned a lot about the human\\n\\nbrain and data structure for fast MIPS in my conversations with ChatGPT.)\\n\\nTypes of Memory\\n\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve\\n\\ninformation. There are several types of memory in human brains.\\n\\n\\x00. Sensory Memory: This is the earliest stage of memory, providing the ability to retain\\n\\nimpressions of sensory information (visual, auditory, etc) after the original stimuli have ended.\\n\\nSensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Faiss\\' → Architecture \\'Mrkl\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Talm\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Chatgpt Plugins\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Toolformer\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Scann\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Openai Api\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Faiss\\' (2 hops, 2 shared entities)\\nDocument text: space, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil\\'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\\n\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case.\\n\\nTheir experiments showed that it was harder to solve verbal math problems than explicitly stated\\n\\nmath problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for\\n\\nthe basic arithmetic reliably. The results highlight when the external symbolic tools can work\\n\\nreliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\n\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al.\\n\\n2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether\\n\\na newly added API call annotation can improve the quality of model outputs. See more details in the\\n\\n“External APIs” section of Prompt Engineering.\\n\\nChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool\\n\\nuse capability working in practice. The collection of tool APIs can be provided by other developers\\n\\n(as in Plugins) or self-defined (as in function calls).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Agent System Overview\\' (2 hops, 2 shared entities)\\nDocument text: Lil\\'Log\\n\\nPosts\\n\\nArchive\\n\\nSearch\\n\\nTags\\n\\nLLM Powered Autonomous Agents\\n\\nDate: June 23, 2023 | Estimated Reading Time: 31 min | Author: Lilian Weng\\n\\nTable of Contents\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several\\n\\nproof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring\\n\\nexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays\\n\\nand programs; it can be framed as a powerful general problem solver.\\n\\nAgent System Overview\\n\\nIn a LLM-powered autonomous agent system, LLM functions as the agentʼs brain, complemented\\n\\nby several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable\\n\\nsubgoals, enabling efficient handling of complex tasks.\\n\\nReflection and refinement: The agent can do self-criticism and self-reflection over past\\n\\nactions, learn from mistakes and refine them for future steps, thereby improving the quality of\\n\\nfinal results.\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as\\n\\nutilizing short-term memory of the model to learn.\\n\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite)\\n\\ninformation over extended periods, often by leveraging an external vector store and fast\\n\\nretrieval.\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model\\n\\nweights (often hard to change after pre-training), including current information, code\\n\\nexecution capability, access to proprietary information sources and more.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\n\\nA complicated task usually involves many steps. An agent needs to know what they are and plan\\n\\nahead.\\n\\nFAQ emojisearch.app\\n\\nLil\\'Log\\n\\nTask Decomposition\\n\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for\\n\\nenhancing model performance on complex tasks. The model is instructed to “think step by step” to\\n\\nutilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT\\n\\ntransforms big tasks into multiple manageable tasks and shed lights into an interpretation of the\\n\\nmodelʼs thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at\\n\\neach step. It first decomposes the problem into multiple thought steps and generates multiple\\n\\nthoughts per step, creating a tree structure. The search process can be BFS (breadth-first search)\\n\\nor DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\n\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\" ,\\n\\n\"What are the subgoals for achieving XYZ?\" , (2) by using task-specific instructions; e.g. \"Write\\n\\na story outline.\" for writing a novel, or (3) with human inputs.\\n'),\n",
       " Document(metadata={'doc_id': 'ff8d7684-c176-403e-b71d-b0c9bca1af7f', 'source': 'lillog_agents.pdf', 'relevance_score': -0.53515625}, page_content=\"happens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimized_retriever.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have an optimized retrieval setup with optimized F1 score (Precision & recall).\n",
    "\n",
    "Now let's proceed to define the LLM generation options config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragbuilder.config.base import LLMConfig\n",
    "\n",
    "gen_config = GenerationOptionsConfig(\n",
    "    llms = [\n",
    "        LLMConfig(type=\"azure_openai\", model_kwargs={'model':'gpt-4o-mini', 'temperature':0.2}),\n",
    "        LLMConfig(type=\"azure_openai\", model_kwargs={'model':'gpt-4o', 'temperature':0.2}),\n",
    "    ],\n",
    "    optimization={\n",
    "        \"n_trials\": 12, \n",
    "        \"n_jobs\": 1,\n",
    "        \"study_name\": \"lillog_agents_study\",\n",
    "        \"optimization_direction\": \"maximize\"\n",
    "    },\n",
    "    evaluation_config={\"type\": \"ragas\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:34:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:34:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Generation Optimization</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Generation Optimization\u001b[0m\u001b[92m ─────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> trial configurations                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generated \u001b[1;36m12\u001b[0m trial configurations                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m0\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m0\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m1\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m1\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m2\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m2\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m3\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m3\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m4\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m4\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">5</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m5\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m5\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m5\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">6</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m6\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m6\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m6\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">7</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m7\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m7\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m7\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">8</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m8\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m8\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m8\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m9\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m9\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m9\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">10</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m10\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m10\u001b[0m                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m10\u001b[0m                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m11\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:06] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m11\u001b[0m                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m11\u001b[0m                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49efb3be4618432aab842ff43ce5d32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating prompt results                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating prompt results                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f08a0bd96714a0389ff80d1a2c8e6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:38:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating final prompt testing results                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:38:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating final prompt testing results                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Average correctness results saved to <span style=\"color: #008000; text-decoration-color: #008000\">'rag_average_correctness_20241231_223853.csv'</span>             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Average correctness results saved to \u001b[32m'rag_average_correctness_20241231_223853.csv'\u001b[0m             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8154</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.8154\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'LLMType.AZURE_OPENAI:gpt-4o'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_template'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful assistant. Answer any questions solely based on the context provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">know.\"\\n\\n&lt;context&gt;\\n{context}\\n&lt;/context&gt;\\n'</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'model'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'LLMType.AZURE_OPENAI:gpt-4o'\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'temperature'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'prompt_template'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'You are a helpful assistant. Answer any questions solely based on the context provided \u001b[0m\n",
       "\u001b[32mbelow. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t \u001b[0m\n",
       "\u001b[32mknow.\"\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</context\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n'\u001b[0m\n",
       "\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GenerationResults(best_config=GenerationConfig(llm=LLMConfig(type=<LLMType.AZURE_OPENAI: 'azure_openai'>, model_kwargs={'model': 'gpt-4o', 'temperature': 0.2}), prompt_template='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n', prompt_key='default_informative'), best_score=0.8154456849114275, best_pipeline={\n",
       "  context: ContextualCompressionRetriever(base_compressor=DocumentCompressorPipeline(transformers=[RerankerLangChainCompressor(model=<rerankers.models.transformer_ranker.TransformerRanker object at 0x569de2480>, kwargs={}, k=3)]), base_retriever=EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x56a0d2fc0>), Neo4jGraphRetriever(graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x3744347a0>, embeddings=AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x377e238f0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x377e22420>, model='text-embedding-3-large', dimensions=None, deployment=None, openai_api_version='2024-02-01', openai_api_base=None, openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=2048, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True, azure_endpoint='https://krux-azure-oai-003.openai.azure.com/', azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True), top_k=20, max_hops=2, max_related_docs_per_doc=3, graph_weight=0.3, index_name='document_embeddings'), VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x377fc0a40>, search_kwargs={'k': 20})], weights=[0.3333333333333333, 0.3333333333333333, 0.3333333333333333])),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| RunnableAssign(mapper={\n",
       "    context: RunnableLambda(itemgetter('context'))\n",
       "             | RunnableLambda(format_docs)\n",
       "  })\n",
       "| RunnableAssign(mapper={\n",
       "    answer: ChatPromptTemplate(input_variables=['context', 'question'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}')), MessagesPlaceholder(variable_name='chat_history', optional=True)])\n",
       "            | AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16534d970>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x165241fd0>, model_name='gpt-4o', temperature=0.2, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://krux-azure-oai-003.openai.azure.com/', openai_api_version='2024-02-01', openai_api_type='azure')\n",
       "            | StrOutputParser()\n",
       "  })\n",
       "| RunnablePick(keys=['answer', 'context']), n_trials=12, completed_trials=12, optimization_time=234.716064, avg_latency=None, error_rate=None, best_prompt='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_generation(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_results = adv_builder.optimization_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = adv_results.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is HNSW?\n",
      "Answer: HNSW (Hierarchical Navigable Small World) is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps, such as the “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {response['question']}\\nAnswer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_ingest\": {\n",
      "    \"score\": 0.7669465389795974,\n",
      "    \"optimization_time\": 50.021133,\n",
      "    \"config\": {\n",
      "      \"document_loader\": \"unstructured\",\n",
      "      \"chunking_strategy\": \"RecursiveCharacterTextSplitter\",\n",
      "      \"chunk_size\": 3000,\n",
      "      \"chunk_overlap\": 100,\n",
      "      \"embedding_model\": \"EmbeddingType.AZURE_OPENAI:text-embedding-3-large\",\n",
      "      \"vector_database\": \"chroma\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 349.08733333333333,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"retrieval\": {\n",
      "    \"score\": 0.9999999999833333,\n",
      "    \"optimization_time\": 74.894355,\n",
      "    \"config\": {\n",
      "      \"retrievers\": [\n",
      "        \"bm25\",\n",
      "        \"graph\",\n",
      "        \"vector_similarity\"\n",
      "      ],\n",
      "      \"top_k\": 3,\n",
      "      \"rerankers\": [\n",
      "        \"BAAI/bge-reranker-base\"\n",
      "      ]\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 1613.4706666666668,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"score\": 0.8154456849114275,\n",
      "    \"optimization_time\": 234.716064,\n",
      "    \"config\": {\n",
      "      \"model\": \"LLMType.AZURE_OPENAI:gpt-4o\",\n",
      "      \"temperature\": 0.2,\n",
      "      \"prompt_template\": \"You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \\\"I don't know.\\\"\\n\\n<context>\\n{context}\\n</context>\\n\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": null,\n",
      "      \"error_rate\": null\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(adv_results.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access individual module components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'doc_id': 'b841a780-cbf5-40fc-9921-029b8ba33b8b', 'source': 'lillog_agents.pdf'}, page_content=\"Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\"),\n",
       "  0.19332719635195306),\n",
       " (Document(metadata={'doc_id': '61ef51b5-89c0-467c-bbb7-8f72163e1d39', 'source': 'lillog_agents.pdf'}, page_content=\"Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\"),\n",
       "  0.19332719635195306),\n",
       " (Document(metadata={'doc_id': 'f022355b-e04a-4137-9d8a-82493f908301', 'source': 'lillog_agents.pdf'}, page_content=\"Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and\\n\\nshould be stopped. Inefficient planning refers to trajectories that take too long without success.\\n\\nHallucination is defined as encountering a sequence of consecutive identical actions that lead to\\n\\nthe same observation in the environment.\\n\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of\\n\\n(failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added\\n\\ninto the agentʼs working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\n\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by\\n\\nexplicitly presenting it with a sequence of past outputs, each annotated with feedback. Human\\n\\nDh = {(x, yi, ri, zi)}n yi\\n\\nfeedback data is a collection of\\n\\nri\\n\\nzi\\n\\nmodel completion,\\n\\nis the human rating of\\n\\n, and\\n\\nx\\n\\nyi\\n\\n, where\\n\\nis the prompt, each\\n\\ni=1 is the corresponding human-provided\\n\\nis a\\n\\nhindsight feedback. Assume the feedback tuples are ranked by reward,\\n\\nrn ≥ rn−1 ≥ ⋯ ≥ r1\\n\\nprocess is supervised fine-tuning where the data is a sequence in the form of yn τh = (x, zi, yi, zj, yj, … , zn, yn) where conditioned on the sequence prefix, such that the model can self-reflect to produce better\\n\\n≤ i ≤ j ≤ n\\n\\n, where\\n\\n. The model is finetuned to only predict\\n\\noutput based on the feedback sequence. The model can optionally receive multiple rounds of\\n\\ninstructions with human annotators at test time.\\n\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-\\n\\ntraining dataset. To avoid shortcutting and copying (because there are many common words in\\n\\nfeedback sequences), they randomly mask 0% - 5% of past tokens during training.\\n\\nThe\\n\\nLil'Log\\n\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization\\n\\nfrom human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\n\\nThe idea of CoH is to present a history of sequentially improved outputs in context and train the\\n\\nmodel to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al.\\n\\n2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where\\n\\nan algorithm is encapsulated in a long history-conditioned policy. Considering that an agent\\n\\ninteracts with the environment many times and in each episode the agent gets a little better, AD\\n\\nconcatenates this learning history and feeds that into the model. Hence we should expect the next\"),\n",
       "  0.16912849177876454),\n",
       " (Document(metadata={'doc_id': '0361daf6-20c6-4d27-8829-78f05e155279', 'source': 'lillog_agents.pdf'}, page_content=\"Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and\\n\\nshould be stopped. Inefficient planning refers to trajectories that take too long without success.\\n\\nHallucination is defined as encountering a sequence of consecutive identical actions that lead to\\n\\nthe same observation in the environment.\\n\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of\\n\\n(failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added\\n\\ninto the agentʼs working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\n\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by\\n\\nexplicitly presenting it with a sequence of past outputs, each annotated with feedback. Human\\n\\nDh = {(x, yi, ri, zi)}n yi\\n\\nfeedback data is a collection of\\n\\nri\\n\\nzi\\n\\nmodel completion,\\n\\nis the human rating of\\n\\n, and\\n\\nx\\n\\nyi\\n\\n, where\\n\\nis the prompt, each\\n\\ni=1 is the corresponding human-provided\\n\\nis a\\n\\nhindsight feedback. Assume the feedback tuples are ranked by reward,\\n\\nrn ≥ rn−1 ≥ ⋯ ≥ r1\\n\\nprocess is supervised fine-tuning where the data is a sequence in the form of yn τh = (x, zi, yi, zj, yj, … , zn, yn) where conditioned on the sequence prefix, such that the model can self-reflect to produce better\\n\\n≤ i ≤ j ≤ n\\n\\n, where\\n\\n. The model is finetuned to only predict\\n\\noutput based on the feedback sequence. The model can optionally receive multiple rounds of\\n\\ninstructions with human annotators at test time.\\n\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-\\n\\ntraining dataset. To avoid shortcutting and copying (because there are many common words in\\n\\nfeedback sequences), they randomly mask 0% - 5% of past tokens during training.\\n\\nThe\\n\\nLil'Log\\n\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization\\n\\nfrom human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\n\\nThe idea of CoH is to present a history of sequentially improved outputs in context and train the\\n\\nmodel to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al.\\n\\n2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where\\n\\nan algorithm is encapsulated in a long history-conditioned policy. Considering that an agent\\n\\ninteracts with the environment many times and in each episode the agent gets a little better, AD\\n\\nconcatenates this learning history and feeds that into the model. Hence we should expect the next\"),\n",
       "  0.16912849177876454)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_results.data_ingest.best_index.similarity_search_with_relevance_scores(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'lillog_agents.pdf', 'relevance_score': 1.8486328125}, page_content=\"experiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\"),\n",
       " Document(metadata={'source': 'lillog_agents.pdf', 'vector_score': 0.5687193870544434, 'type': 'primary', 'relevance_score': 1.509765625}, page_content='[Vector Search Result - Score: 0.569]\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil\\'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nRelated Documents:\\n\\n[Graph-Connected Document - Score: 0.848]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Explicitmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Explicitmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\nDocument text: into a neural network by performing behavioral cloning over actions. The history data is generated\\n\\nby a set of source policies, each trained for a specific task. At the training stage, during each RL\\n\\nrun, a random task is sampled and a subsequence of multi-episode history is used for training,\\n\\nsuch that the learned policy is task-agnostic.\\n\\nIn reality, the model has limited context window length, so episodes should be short enough to\\n\\nconstruct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a\\n\\nnear-optimal in-context RL algorithm. The emergence of in-context RL requires long enough\\n\\ncontext.\\n\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert\\n\\ntrajectories instead of learning history), source policy (used for generating trajectories for\\n\\ndistillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD\\n\\ndemonstrates in-context RL with performance getting close to RL^2 despite only using offline RL\\n\\nand learns much faster than other baselines. When conditioned on partial training history of the\\n\\nsource policy, AD also improves much faster than ED baseline.\\n\\nLil\\'Log\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze. (Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory\\n\\n(Big thank you to ChatGPT for helping me draft this section. Iʼve learned a lot about the human\\n\\nbrain and data structure for fast MIPS in my conversations with ChatGPT.)\\n\\nTypes of Memory\\n\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve\\n\\ninformation. There are several types of memory in human brains.\\n\\n\\x00. Sensory Memory: This is the earliest stage of memory, providing the ability to retain\\n\\nimpressions of sensory information (visual, auditory, etc) after the original stimuli have ended.\\n\\nSensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Faiss\\' → Architecture \\'Mrkl\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Talm\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Chatgpt Plugins\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Toolformer\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Scann\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Openai Api\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Faiss\\' (2 hops, 2 shared entities)\\nDocument text: space, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil\\'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\\n\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case.\\n\\nTheir experiments showed that it was harder to solve verbal math problems than explicitly stated\\n\\nmath problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for\\n\\nthe basic arithmetic reliably. The results highlight when the external symbolic tools can work\\n\\nreliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\n\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al.\\n\\n2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether\\n\\na newly added API call annotation can improve the quality of model outputs. See more details in the\\n\\n“External APIs” section of Prompt Engineering.\\n\\nChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool\\n\\nuse capability working in practice. The collection of tool APIs can be provided by other developers\\n\\n(as in Plugins) or self-defined (as in function calls).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Agent System Overview\\' (2 hops, 2 shared entities)\\nDocument text: Lil\\'Log\\n\\nPosts\\n\\nArchive\\n\\nSearch\\n\\nTags\\n\\nLLM Powered Autonomous Agents\\n\\nDate: June 23, 2023 | Estimated Reading Time: 31 min | Author: Lilian Weng\\n\\nTable of Contents\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several\\n\\nproof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring\\n\\nexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays\\n\\nand programs; it can be framed as a powerful general problem solver.\\n\\nAgent System Overview\\n\\nIn a LLM-powered autonomous agent system, LLM functions as the agentʼs brain, complemented\\n\\nby several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable\\n\\nsubgoals, enabling efficient handling of complex tasks.\\n\\nReflection and refinement: The agent can do self-criticism and self-reflection over past\\n\\nactions, learn from mistakes and refine them for future steps, thereby improving the quality of\\n\\nfinal results.\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as\\n\\nutilizing short-term memory of the model to learn.\\n\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite)\\n\\ninformation over extended periods, often by leveraging an external vector store and fast\\n\\nretrieval.\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model\\n\\nweights (often hard to change after pre-training), including current information, code\\n\\nexecution capability, access to proprietary information sources and more.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\n\\nA complicated task usually involves many steps. An agent needs to know what they are and plan\\n\\nahead.\\n\\nFAQ emojisearch.app\\n\\nLil\\'Log\\n\\nTask Decomposition\\n\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for\\n\\nenhancing model performance on complex tasks. The model is instructed to “think step by step” to\\n\\nutilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT\\n\\ntransforms big tasks into multiple manageable tasks and shed lights into an interpretation of the\\n\\nmodelʼs thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at\\n\\neach step. It first decomposes the problem into multiple thought steps and generates multiple\\n\\nthoughts per step, creating a tree structure. The search process can be BFS (breadth-first search)\\n\\nor DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\n\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\" ,\\n\\n\"What are the subgoals for achieving XYZ?\" , (2) by using task-specific instructions; e.g. \"Write\\n\\na story outline.\" for writing a novel, or (3) with human inputs.\\n'),\n",
       " Document(metadata={'doc_id': 'ff8d7684-c176-403e-b71d-b0c9bca1af7f', 'source': 'lillog_agents.pdf', 'relevance_score': -0.53515625}, page_content=\"happens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_results.retrieval.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:46:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting RAG server on <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://0.0.0.0:8005</span>                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:46:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting RAG server on \u001b[4;94mhttp://0.0.0.0:8005\u001b[0m                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [3063]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [3063]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This will return API endpoint\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# localhost:60001/retreive -- retriever only\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# localhost:60001/invoke -- RAG\u001b[39;00m\n",
      "File \u001b[0;32m~/KruxAI/ragbuilder/src/ragbuilder/core/builder.py:433\u001b[0m, in \u001b[0;36mRAGBuilder.serve\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m HTTPException(status_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting RAG server on http://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 433\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun(\u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/main.py:577\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    575\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:65\u001b[0m, in \u001b[0;36mServer.run\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/events.py:88\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:396\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:303\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    301\u001b[0m _enter_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step_run_and_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     _leave_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:68\u001b[0m, in \u001b[0;36mServer.serve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:328\u001b[0m, in \u001b[0;36mServer.capture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_signals):\n\u001b[0;32m--> 328\u001b[0m     \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_signal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "builder.serve()\n",
    "# This will return API endpoint\n",
    "# localhost:60001/retreive -- retriever only\n",
    "# localhost:60001/invoke -- RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
